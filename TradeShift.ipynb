{
 "metadata": {
  "name": "",
  "signature": "sha256:4054ffd8d02bcddd432bb8d086fbaf06b010430948c9156ea33266bb13ec32f7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "pwd"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run fast_solution.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-11 08:34:27.573000\tencountered: 100000\tcurrent logloss: 0.027061\n",
        "2014-10-11 08:41:59.140000\tencountered: 200000\tcurrent logloss: 0.023047"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 08:49:32.417000\tencountered: 300000\tcurrent logloss: 0.020879"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 08:57:12.101000\tencountered: 400000\tcurrent logloss: 0.019529"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:04:48.219000\tencountered: 500000\tcurrent logloss: 0.018498"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:12:26.263000\tencountered: 600000\tcurrent logloss: 0.017736"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:20:10.174000\tencountered: 700000\tcurrent logloss: 0.017139"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:27:53.420000\tencountered: 800000\tcurrent logloss: 0.016632"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:35:33.676000\tencountered: 900000\tcurrent logloss: 0.016207"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:43:18.395000\tencountered: 1000000\tcurrent logloss: 0.015834"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:51:02.797000\tencountered: 1100000\tcurrent logloss: 0.015498"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 09:58:54.950000\tencountered: 1200000\tcurrent logloss: 0.015205"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 10:06:42.771000\tencountered: 1300000\tcurrent logloss: 0.014940"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 10:14:33.703000\tencountered: 1400000\tcurrent logloss: 0.014705"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 10:22:32.112000\tencountered: 1500000\tcurrent logloss: 0.014485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 10:30:27.155000\tencountered: 1600000\tcurrent logloss: 0.014278"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-11 10:38:21.661000\tencountered: 1700000\tcurrent logloss: 0.014093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done, elapsed time: 2:21:34.423000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import csv\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "train_pd = pd.read_csv('Trade Shift/train.csv',header=0, nrows=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_pd.x8.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x16f81128>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJkiRJkiRJkiRJkiRJktQ7/w+XP3HDWpuOtAAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x16f81438>"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "u'C:\\\\Users\\\\SYan\\\\Desktop\\\\IPython Notebooks'"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ../Kaggle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\SYan\\Desktop\\Kaggle\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd 'Trade Shift/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\SYan\\Desktop\\Kaggle\\Trade Shift\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "edit hashing_feature.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load hashing_feature.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "\"\"\"\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0)\n",
      "raw_test = pd.read_csv('test.csv', header=0)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 200000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "#test = raw_test\n",
      "#del raw_test\n",
      "\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows] \n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v):\n",
      "    table = {}\n",
      "    for key in v:\n",
      "        if not key in table:\n",
      "            table[key] = 1\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    temp = v\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        temp[ind[count]] = hashT[key]\n",
      "        count = count + 1\n",
      "    return temp\n",
      "        \n",
      "\n",
      "\n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        temp = train[i].fillna('other')\n",
      "        table = freq(temp)\n",
      "        train[i] = lookup(table, temp)\n",
      "        \n",
      "        temp = validation[i].fillna('other')\n",
      "        table = freq(temp)\n",
      "        validation[i] = lookup(table, temp)\n",
      "    \n",
      "        temp = test[i].fillna('other')\n",
      "        table = freq(temp)\n",
      "        test[i] = lookup(table, temp)  \n",
      "    else:\n",
      "        mean = train[i].mean()\n",
      "        temp = train[i].fillna(mean)\n",
      "        train[i] = temp\n",
      "        \n",
      "        temp = validation[i].fillna(mean)\n",
      "        validation[i] = temp\n",
      "        \n",
      "        temp = test[i].fillna(mean)\n",
      "        test[i] = temp\n",
      "    # scaling    \n",
      "    train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "    validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "    test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "    \n",
      "    if any(train[i].isnull()):\n",
      "        print i\n",
      "\n",
      "del temp\n",
      "del table\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "# Model training ###################################################\n",
      "        \n",
      "print \"Step3: Start training models\"       \n",
      "\n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = set(label)\n",
      "count = 0\n",
      "model = {}\n",
      "\n",
      "outfile = open('./submission_new.csv', 'w')\n",
      "outfile.write('id_label, pred\\n')\n",
      "    \n",
      "for k in K:\n",
      "    if k != 'y14' and  k != 'id':\n",
      "        forest = RandomForestClassifier(n_estimators = 200, verbose = 0, n_jobs = 4)\n",
      "       #No 'y14' or 'id'    \n",
      "        model[k] = forest.fit(train.drop('id', 1), label[k])\n",
      "        output_validation = model[k].predict_proba(validation.drop('id', 1))\n",
      "        print \"\\n\", k, \"AUC = \", metrics.roc_auc_score(label_validation[k], output_validation[:,1])\n",
      "        count += 1\n",
      "\"\"\"       \n",
      "for i in range(len(test)):\n",
      "    for k in {'y1','y3','y8','y9'}:\n",
      "        #print k\n",
      "        if k != 'y14' and  k != 'id':\n",
      "            output = model[k].predict_proba(test.drop('id', 1).ix[i])\n",
      "            outfile.write('%s_%s,%s\\n' % (test.id[i], k, output[0][1]))\n",
      "        elif k == 'y14':\n",
      "            outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "\"\"\"           \n",
      "\n",
      "    \n",
      "outfile.close()\n",
      "print('Training is done, elapsed time: %s' % str(datetime.now() - p1))           \n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step1: Sampling\n",
        "Step2: Hashing Frequency Table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sampling and hashing are done, elapsed time: 0:07:22.736000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step3: Start training models\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y9 AUC =  0.995972842807\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y8 AUC =  0.906103561541\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y1 AUC =  0.985137189811\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y3 AUC =  0.999991236682\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y2 AUC =  0.996222450154\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y5 AUC =  1.0\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y4 AUC =  0.999762056914\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y7 AUC =  0.989257854775\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y6 AUC =  0.992532041037\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y28 AUC =  0.988652735421\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y29 AUC =  0.994219551409\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y20 AUC =  0.999674273303\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y21 AUC =  0.999843650952\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y22 AUC =  0.998986669718\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y23 AUC =  0.999951692634\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y24 AUC =  0.99732417377\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y25 AUC =  0.993645838998\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y26 AUC =  0.991485108829\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y27 AUC =  0.997673528268\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y33 AUC =  0.988226156279\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y32 AUC =  0.996733878269\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y31 AUC =  0.996699491277\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y30 AUC =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.99394163446\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y19 AUC =  0.995185210669\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y18 AUC =  0.79135391924\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y15 AUC =  0.999721000124\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y17 AUC =  0.79450542124\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y16 AUC =  0.998634619873\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y11 AUC =  0.932124894997\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y10 AUC =  0.985811185592\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y13 AUC =  0.992944908454\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y12 AUC =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.991568300275\n",
        "Training is done, elapsed time: 2:41:07.258000\n",
        "Done, elapsed time: 2:48:29.994000\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{'y1': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y10': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y11': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y12': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y13': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y15': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y16': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y17': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y18': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y19': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y2': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y20': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y21': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y22': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y23': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y24': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y25': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y26': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y27': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y28': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y29': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y3': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y30': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y31': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y32': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y33': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y4': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y5': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y6': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y7': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y8': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0),\n",
        " 'y9': RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "             criterion='gini', max_depth=None, max_features='auto',\n",
        "             min_density=None, min_samples_leaf=1, min_samples_split=2,\n",
        "             n_estimators=200, n_jobs=4, oob_score=False, random_state=None,\n",
        "             verbose=0)}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('./submission_new.csv', 'w') as outfile:\n",
      "    outfile.write('id_label, pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(test))\n",
      "    #n = range(100)\n",
      "  \n",
      "    for k in K:    \n",
      "        if k != 'y14' and  k != 'id':\n",
      "            output[k] = model[k].predict_proba(test.drop('id', 1))\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 100000 == 0:\n",
      "            print i\n",
      "        for k in K:\n",
      "            if k == 'y14':\n",
      "                outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "            elif k!= 'id':\n",
      "                outfile.write('%s_%s,%s\\n' % (test.id[i], k, output[k][i,1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output['y1']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "array([[ 0.965,  0.035],\n",
        "       [ 0.965,  0.035],\n",
        "       [ 0.93 ,  0.07 ],\n",
        "       ..., \n",
        "       [ 0.985,  0.015],\n",
        "       [ 1.   ,  0.   ],\n",
        "       [ 0.995,  0.005]])"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'model' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-458d5f1afc81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "u'C:\\\\Users\\\\SYan\\\\Desktop\\\\IPython Notebooks'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '../Kaggle/Trade Shift/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\SYan\\Desktop\\Kaggle\\Trade Shift\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load hashing_feature.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('./submission_new.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(test))\n",
      "    #n = range(100)\n",
      "    \n",
      "    K = range(33)\n",
      "    for k in K:\n",
      "        key = 'y' + str(k + 1)\n",
      "        if k != 13:\n",
      "            output[key] = model[key].predict_proba(test.drop('id', 1))\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 100000 == 0:\n",
      "            print i\n",
      "        for k in K:\n",
      "            key = 'y' + str(k + 1) \n",
      "            if k == 13:\n",
      "                outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "            else:\n",
      "                outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(output[key][i,1])))\n",
      "                #val = output[key][i,1]\n",
      "                #if val < 1e-10:\n",
      "                    #outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(val + 1e-10)))\n",
      "                #elif val == 1.0:\n",
      "                    #outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(val - 1e-10)))\n",
      "                #else:\n",
      "                    #outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(val)))\n",
      "           \n",
      "\n",
      "    \n",
      "outfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load hashing_feature.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "#\"\"\"\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0)\n",
      "raw_test = pd.read_csv('test.csv', header=0)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 10000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "test = raw_test\n",
      "\n",
      "del raw_test\n",
      "del raw_train\n",
      "del raw_label\n",
      "\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows] \n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v):\n",
      "    table = {}\n",
      "    for key in v:\n",
      "        if not key in table:\n",
      "            table[key] = 1\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    temp = v\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        temp[ind[count]] = hashT[key]\n",
      "        count = count + 1\n",
      "    return temp\n",
      "        \n",
      "\n",
      "\n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        temp = train[i].fillna('other')\n",
      "        table = freq(temp)\n",
      "        train[i] = lookup(table, temp)\n",
      "        \n",
      "        temp = validation[i].fillna('other')\n",
      "        table = freq(temp)\n",
      "        validation[i] = lookup(table, temp)\n",
      "    \n",
      "        temp = test[i].fillna('other')\n",
      "        table = freq(temp)\n",
      "        test[i] = lookup(table, temp)  \n",
      "    else:\n",
      "        mean = train[i].mean()\n",
      "        temp = train[i].fillna(mean)\n",
      "        train[i] = temp\n",
      "        \n",
      "        temp = validation[i].fillna(mean)\n",
      "        validation[i] = temp\n",
      "        \n",
      "        temp = test[i].fillna(mean)\n",
      "        test[i] = temp\n",
      "    # scaling    \n",
      "    train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "    validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "    test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "    \n",
      "    if any(train[i].isnull()):\n",
      "        print i\n",
      "\n",
      "del temp\n",
      "del table\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "# Model training ###################################################\n",
      "        \n",
      "print \"Step3: Start training models\"       \n",
      "\n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = set(label)\n",
      "count = 0\n",
      "model = {}\n",
      "\n",
      "outfile = open('./submission_new.csv', 'w')\n",
      "outfile.write('id_label,pred\\n')\n",
      "\n",
      "log_loss = {}\n",
      "\n",
      "for k in K:\n",
      "    if k != 'y14' and  k != 'id':\n",
      "        forest = RandomForestClassifier(n_estimators = 100, criterion = \"entropy\", verbose = 0, n_jobs = 4, min_samples_split = 50)\n",
      "       # No 'y14' or 'id'    \n",
      "        model[k] = forest.fit(train.drop('id', 1), label[k])\n",
      "        output_validation = model[k].predict_proba(validation.drop('id', 1))\n",
      "\tlog_loss.append( metrics.log_loss(label_validation[k].as_matrix(), output_validation) )\n",
      "        #print \"\\n\", k, \"AUC = \", metrics.roc_auc_score(label_validation[k], output_validation[:,1])\n",
      "\tprint \"\\n\", k, \"Log_Loss = \", log_loss[count]\n",
      "        count += 1\n",
      "\n",
      "print('\\nTotal Log Loss = ', sum(log_loss) / 33, '\\n')\n",
      "p1 = datetime.now()\n",
      "print('Training is done, elapsed time: %s' % str(p2 - p1))\n",
      "\n",
      "# Saving submission #######################################################################\n",
      "\n",
      "with open('./submission_new.csv', 'w') as outfile:\n",
      "    outfile.write('id_label, pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(test))\n",
      "    #n = range(100)\n",
      "  \n",
      "    for k in K:    \n",
      "        if k != 'y14' and  k != 'id':\n",
      "            output[k] = model[k].predict_proba(test.drop('id', 1))\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 100000 == 0:\n",
      "            print i\n",
      "        for k in K:\n",
      "            if k == 'y14':\n",
      "                outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "            elif k!= 'id':\n",
      "                outfile.write('%s_%s,%s\\n' % (test.id[i], k, output[k][i,1]))\n",
      "    \n",
      "outfile.close()\n",
      "print('Dumping is done, elapsed time: %s' % str(datetime.now() - p2))           \n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step0: Loading raw data\n",
        "Data loading is done! elapsed time: 0:02:04.426000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step1: Sampling\n",
        "Step2: Hashing Frequency Table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sampling and hashing are done, elapsed time: 0:07:42.744000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step3: Start training models\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y9 Log_Loss =  0.0892624128252\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y8 Log_Loss =  0.00292740405608\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y1 Log_Loss =  0.016911766404\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y3 Log_Loss =  0.0211944356547\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y2 Log_Loss =  0.00479230987495\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y5 Log_Loss =  -0.0\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y4 Log_Loss =  0.0178719953103\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y7 Log_Loss =  0.0862240585331\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y6 Log_Loss =  0.101992671072\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y28 Log_Loss =  0.0326628819192\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y29 Log_Loss =  0.0715520666259\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y20 Log_Loss =  0.00791131786194\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y21 Log_Loss =  0.0194661425937\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y22 Log_Loss =  0.0218020720157\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y23 Log_Loss =  0.00384438130077\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y24 Log_Loss =  0.0414885869609\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y25 Log_Loss =  0.00529342935807\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y26 Log_Loss =  0.0468145528398\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y27 Log_Loss =  0.0323860734578\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y33 Log_Loss =  0.304610789025\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y32 Log_Loss =  0.0784883872985\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y31 Log_Loss =  0.0629592659952\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y30 Log_Loss =  0.0545522206786\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y19 Log_Loss =  0.000630978721116\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y18 Log_Loss =  0.000228510492288\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y15 Log_Loss =  0.0105729371034\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y17 Log_Loss =  -0.0\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y16 Log_Loss =  0.0251410510255\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y11 Log_Loss =  0.00504130613807\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y10 Log_Loss =  0.0419608380162\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y13 Log_Loss =  0.0548974730368\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y12 Log_Loss =  0.100075698734\n",
        "('\\nTotal Log Loss = ', 0.041319939846343842, '\\n')\n",
        "Training is done, elapsed time: -2 days, 22:54:33.453000\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "IndexError",
       "evalue": "index 1 is out of bounds for axis 1 with size 1",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-131-a262ba87fcae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s_y14,0.0\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m                 \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s_%s,%s\\n'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "key"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 134,
       "text": [
        "'y5'"
       ]
      }
     ],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output['y5']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 135,
       "text": [
        "array([[ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       ..., \n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.]])"
       ]
      }
     ],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted(log_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 137,
       "text": [
        "[-0.0,\n",
        " -0.0,\n",
        " 0.00022851049228781424,\n",
        " 0.00063097872111579027,\n",
        " 0.0029274040560787729,\n",
        " 0.0038443813007659486,\n",
        " 0.0047923098749506178,\n",
        " 0.0050413061380663099,\n",
        " 0.0052934293580725982,\n",
        " 0.0079113178619402563,\n",
        " 0.010572937103383985,\n",
        " 0.016911766404015722,\n",
        " 0.017871995310312971,\n",
        " 0.01946614259372878,\n",
        " 0.021194435654650026,\n",
        " 0.021802072015683335,\n",
        " 0.025141051025490538,\n",
        " 0.032386073457787781,\n",
        " 0.032662881919211559,\n",
        " 0.041488586960882805,\n",
        " 0.041960838016221289,\n",
        " 0.046814552839800766,\n",
        " 0.054552220678647088,\n",
        " 0.05489747303682329,\n",
        " 0.062959265995242986,\n",
        " 0.071552066625919453,\n",
        " 0.078488387298515691,\n",
        " 0.086224058533052247,\n",
        " 0.089262412825200324,\n",
        " 0.10007569873378523,\n",
        " 0.1019926710723715,\n",
        " 0.30461078902534128]"
       ]
      }
     ],
     "prompt_number": 137
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "u'C:\\\\Users\\\\SYan\\\\Desktop\\\\Kaggle\\\\Trade Shift'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '../Kaggle/Trade Shift'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\SYan\\Desktop\\Kaggle\\Trade Shift\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load hashing_feature_new.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "#\"\"\"\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0, nrows = 10000)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0, nrows = 10000)\n",
      "raw_test = pd.read_csv('test.csv', header=0, nrows = 10000)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 10000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "test = raw_test\n",
      "\n",
      "del raw_test\n",
      "del raw_train\n",
      "del raw_label\n",
      "\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v, table):\n",
      "    for key in v:\n",
      "        if not key in table or key == 'YES':\n",
      "            table[key] = 1\n",
      "        elif key == 'NO':\n",
      "            table[key] = 0\n",
      "        elif key == '' or key == '-999':\n",
      "            table[key] = -999\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        if key in hashT:\n",
      "            v[ind[count]] = hashT[key]\n",
      "        else:\n",
      "            v[ind[count]] = 0\n",
      "        count = count + 1\n",
      "    return v\n",
      "\n",
      "\n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "train = train.fillna('-999')\n",
      "test = test.fillna('-999')\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        table = freq(train[i], table)\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        train[i] = lookup(table, train[i])\n",
      "        test[i] = lookup(table, test[i])\n",
      "\n",
      "# Split the train into training and validation\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows]\n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "# scaling    \n",
      "#train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "#validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "#test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "\n",
      "del table\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "# Model training ###################################################\n",
      "'''\n",
      "print \"Step3: Start training models\"       \n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = set(label)\n",
      "count = 0\n",
      "model = {}\n",
      "log_loss = {}\n",
      "\n",
      "for k in K:\n",
      "        forest = RandomForestClassifier(n_estimators = 40, criterion = \"gini\", verbose = 0, n_jobs = 4, min_samples_split = 50)\n",
      "       # No 'y14' or 'id'    \n",
      "        model[k] = forest.fit(train.drop('id', 1), label[k])\n",
      "        output_validation = model[k].predict_proba(validation.drop('id', 1))\n",
      "        log_loss[k] = metrics.log_loss(label_validation[k].as_matrix(), output_validation)\n",
      "        #print \"\\n\", k, \"AUC = \", metrics.roc_auc_score(label_validation[k], output_validation[:,1])\n",
      "        print \"\\n\", k, \"Log_Loss = \", log_loss[k]\n",
      "        count += 1\n",
      "\n",
      "print('\\nTotal Log Loss = ', sum(log_loss.values()) / 33, '\\n')\n",
      "p2 = datetime.now()\n",
      "print('Training is done, elapsed time: %s' % str(p2 - p1))\n",
      "\n",
      "# Saving submission #######################################################################\n",
      "\n",
      "with open('./submission_new.csv', 'w') as outfile:\n",
      "    outfile.write('id_label, pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(test))\n",
      "    #n = range(100)\n",
      "\n",
      "    K = range(33)\n",
      "    for k in K:\n",
      "        key = 'y' + str(k + 1)\n",
      "        if k != 13:\n",
      "            output[key] = model[key].predict_proba(test.drop('id', 1))\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 100000 == 0:\n",
      "            print i\n",
      "        for k in K:\n",
      "            key = 'y' + str(k + 1) \n",
      "            if k == 13:\n",
      "                outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "            else:\n",
      "                outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(output[key][i,1])))\n",
      "    \n",
      "outfile.close()\n",
      "print('Dumping is done, elapsed time: %s' % str(datetime.now() - p2))           \n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step0: Loading raw data\n",
        "Data loading is done! elapsed time: 0:00:00.593000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step1: Sampling\n",
        "Step2: Hashing Frequency Table\n",
        "Sampling and hashing are done, elapsed time: 0:00:11.363000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "'\\nprint \"Step3: Start training models\"       \\n\\n# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\\nK = set(label)\\ncount = 0\\nmodel = {}\\nlog_loss = {}\\n\\nfor k in K:\\n        forest = RandomForestClassifier(n_estimators = 40, criterion = \"gini\", verbose = 0, n_jobs = 4, min_samples_split = 50)\\n       # No \\'y14\\' or \\'id\\'    \\n        model[k] = forest.fit(train.drop(\\'id\\', 1), label[k])\\n        output_validation = model[k].predict_proba(validation.drop(\\'id\\', 1))\\n        log_loss[k] = metrics.log_loss(label_validation[k].as_matrix(), output_validation)\\n        #print \"\\n\", k, \"AUC = \", metrics.roc_auc_score(label_validation[k], output_validation[:,1])\\n        print \"\\n\", k, \"Log_Loss = \", log_loss[k]\\n        count += 1\\n\\nprint(\\'\\nTotal Log Loss = \\', sum(log_loss.values()) / 33, \\'\\n\\')\\np2 = datetime.now()\\nprint(\\'Training is done, elapsed time: %s\\' % str(p2 - p1))\\n\\n# Saving submission #######################################################################\\n\\nwith open(\\'./submission_new.csv\\', \\'w\\') as outfile:\\n    outfile.write(\\'id_label, pred\\n\\')\\n    output = {}\\n    n = range(len(test))\\n    #n = range(100)\\n\\n    K = range(33)\\n    for k in K:\\n        key = \\'y\\' + str(k + 1)\\n        if k != 13:\\n            output[key] = model[key].predict_proba(test.drop(\\'id\\', 1))\\n                     \\n    for i in n:\\n        if i % 100000 == 0:\\n            print i\\n        for k in K:\\n            key = \\'y\\' + str(k + 1) \\n            if k == 13:\\n                outfile.write(\\'%s_y14,0.0\\n\\' % test.id[i])\\n            else:\\n                outfile.write(\\'%s_%s,%s\\n\\' % (test.id[i], key, str(output[key][i,1])))\\n    \\noutfile.close()\\nprint(\\'Dumping is done, elapsed time: %s\\' % str(datetime.now() - p2))           \\n\\nprint(\\'Done, elapsed time: %s\\' % str(datetime.now() - start))\\n'"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load hashing_feature_new.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "#\"\"\"\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0)\n",
      "raw_test = pd.read_csv('test.csv', header=0)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 100000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "test = raw_test\n",
      "\n",
      "del raw_test\n",
      "del raw_train\n",
      "del raw_label\n",
      "\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v, table):\n",
      "    for key in v:\n",
      "        if not key in table or key == 'YES':\n",
      "            table[key] = 1\n",
      "        elif key == 'NO':\n",
      "            table[key] = 0\n",
      "        elif key == '' or key == '-999':\n",
      "            table[key] = -999\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        if key in hashT:\n",
      "            v[ind[count]] = hashT[key]\n",
      "        else:\n",
      "            v[ind[count]] = 0\n",
      "        count = count + 1\n",
      "    return v\n",
      "\n",
      "\n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "train = train.fillna('-999')\n",
      "test = test.fillna('-999')\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        table = freq(train[i], table)\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        train[i] = lookup(table, train[i])\n",
      "\ttest[i] = lookup(table, test[i])\n",
      "\n",
      "# Split the train into training and validation\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows]\n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "# scaling    \n",
      "#train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "#validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "#test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "\n",
      "del table\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "# Model training ###################################################\n",
      "        \n",
      "print \"Step3: Start training models\"       \n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = set(label)\n",
      "count = 0\n",
      "model = {}\n",
      "log_loss = {}\n",
      "\n",
      "for k in K:\n",
      "    if k != 'y14' and  k != 'id':\n",
      "        forest = RandomForestClassifier(n_estimators = 50, criterion = \"entropy\", verbose = 0, n_jobs = 4, min_samples_split=10)\n",
      "       # No 'y14' or 'id'    \n",
      "        model[k] = forest.fit(train.drop('id', 1), label[k])\n",
      "        output_validation = model[k].predict_proba(validation.drop('id', 1))\n",
      "        log_loss[k] = metrics.log_loss(label_validation[k].as_matrix(), output_validation)\n",
      "        #print \"\\n\", k, \"AUC = \", metrics.roc_auc_score(label_validation[k], output_validation[:,1])\n",
      "        print \"\\n\", k, \"Log_Loss = \", log_loss[k]\n",
      "        count += 1\n",
      "\n",
      "print('\\nTotal Log Loss = ', sum(log_loss.values()) / 33, '\\n')\n",
      "p2 = datetime.now()\n",
      "print('Training is done, elapsed time: %s' % str(p2 - p1))\n",
      "\n",
      "# Saving submission #######################################################################\n",
      "\n",
      "with open('./submission_new.csv', 'w') as outfile:\n",
      "    outfile.write('id_label, pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(test))\n",
      "    #n = range(100)\n",
      "\n",
      "    K = range(33)\n",
      "    for k in K:\n",
      "        key = 'y' + str(k + 1)\n",
      "        if k != 13:\n",
      "            output[key] = model[key].predict_proba(test.drop('id', 1))\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 100000 == 0:\n",
      "            print i\n",
      "        for k in K:\n",
      "            key = 'y' + str(k + 1) \n",
      "            if k == 13:\n",
      "                outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "            else:\n",
      "                outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(output[key][i,1])))\n",
      "    \n",
      "print('Dumping is done, elapsed time: %s' % str(datetime.now() - p2))           \n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step0: Loading raw data\n",
        "Data loading is done! elapsed time: 0:01:45.721000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step1: Sampling\n",
        "Step2: Hashing Frequency Table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Sampling and hashing are done, elapsed time: 0:07:56.295000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step3: Start training models\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y9 Log_Loss =  0.0591703648204\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y8 Log_Loss =  0.00395367394835\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y1 Log_Loss =  0.00993994680413\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y3 Log_Loss =  0.00472939123005\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y2 Log_Loss =  0.00130706917796\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y5 Log_Loss =  0.00350204605634\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y4 Log_Loss =  0.00652495980814\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y7 Log_Loss =  0.0478335405471\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y6 Log_Loss =  0.0561511026411\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y28 Log_Loss =  0.0188670438481\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y29 Log_Loss =  0.0388293845322\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y20 Log_Loss =  0.00126930647378\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y21 Log_Loss =  0.00511643289022\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y22 Log_Loss =  0.00431687472248\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y23 Log_Loss =  0.00105414418806\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y24 Log_Loss =  0.0178657037766\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y25 Log_Loss =  0.00198110598351\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y26 Log_Loss =  0.0151771151046\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y27 Log_Loss =  0.00712896090966\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y33 Log_Loss =  0.169947744461\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y32 Log_Loss =  0.0260572777857\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y31 Log_Loss =  0.0264208178578\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y30 Log_Loss =  0.0232274431884\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y19 Log_Loss =  0.000809849315819\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y18 Log_Loss =  0.00201566450716\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y15 Log_Loss =  0.00385944319304\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y17 Log_Loss =  0.00204639961731\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y16 Log_Loss =  0.00980052948051\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y11 Log_Loss =  0.00107697592268\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y10 Log_Loss =  0.0353525430081\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y13 Log_Loss =  0.0126858440266\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "y12 Log_Loss =  0.062262358707\n",
        "('\\nTotal Log Loss = ', 0.020614577531321208, '\\n')\n",
        "Training is done, elapsed time: 0:11:24.138000\n",
        "0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "100000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "200000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "300000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "400000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "500000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Dumping is done, elapsed time: 0:13:52.879000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done, elapsed time: 0:33:13.312000\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load fast_solution.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "                   Version 2, December 2004\n",
      "\n",
      "Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n",
      "\n",
      "Everyone is permitted to copy and distribute verbatim or modified\n",
      "copies of this license document, and changing it is allowed as long\n",
      "as the name is changed.\n",
      "\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "  TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n",
      "\n",
      " 0. You just DO WHAT THE FUCK YOU WANT TO.\n",
      "'''\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "from math import log, exp, sqrt\n",
      "\n",
      "\n",
      "# TL; DR\n",
      "# the main learning process start at line 122\n",
      "\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "train = 'train.csv'  # path to training file\n",
      "label = 'trainLabels.csv'  # path to label file of training data\n",
      "test = 'test.csv'  # path to testing file\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "# A. x, y generator\n",
      "# INPUT:\n",
      "#     path: path to train.csv or test.csv\n",
      "#     label_path: (optional) path to trainLabels.csv\n",
      "# YIELDS:\n",
      "#     ID: id of the instance (can also acts as instance count)\n",
      "#     x: a list of indices that its value is 1\n",
      "#     y: (if label_path is present) label value of y1 to y33\n",
      "def data(path, label_path=None):\n",
      "    for t, line in enumerate(open(path)):\n",
      "        #if t > 100:\n",
      "            #break\n",
      "        \n",
      "        # initialize our generator\n",
      "        if t == 0:\n",
      "            # create a static x,\n",
      "            # so we don't have to construct a new x for every instance\n",
      "            x = [0] * (146 + 46)\n",
      "            if label_path:\n",
      "                label = open(label_path)\n",
      "                label.readline()  # we don't need the headers\n",
      "            continue\n",
      "        # parse x\n",
      "        for m, feat in enumerate(line.rstrip().split(',')):\n",
      "            if m == 0:\n",
      "                ID = int(feat)\n",
      "            else:\n",
      "                # one-hot encode everything with hash trick\n",
      "                # categorical: one-hotted\n",
      "                # boolean: ONE-HOTTED\n",
      "                # numerical: ONE-HOTTED!\n",
      "                # note, the build in hash(), although fast is not stable,\n",
      "                #       i.e., same value won't always have the same hash\n",
      "                #       on different machines\n",
      "                x[m] = abs(hash(str(m) + '_' + feat)) % D\n",
      "        \n",
      "        row = line.rstrip().split(',')\n",
      "        hash_cols = [3,4,34,35,61,64,65,91,94,95]\n",
      "        t = 146\n",
      "        for i in xrange(10):\n",
      "          for j in xrange(i+1, 10):\n",
      "            t += 1\n",
      "            x[t] = abs(hash(row[hash_cols[i]]+\"_x_\"+row[hash_cols[j]])) % D\n",
      "\n",
      "        #print len(x), x[0:10]\n",
      "        # parse y, if provided\n",
      "        if label_path:\n",
      "            # use float() to prevent future type casting, [1:] to ignore id\n",
      "            y = [float(y) for y in label.readline().split(',')[1:]]\n",
      "        yield (ID, x, y) if label_path else (ID, x)\n",
      "\n",
      "\n",
      "# B. Bounded logloss\n",
      "# INPUT:\n",
      "#     p: our prediction\n",
      "#     y: real answer\n",
      "# OUTPUT\n",
      "#     bounded logarithmic loss of p given y\n",
      "def logloss(p, y):\n",
      "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
      "    return -log(p) if y == 1. else -log(1. - p)\n",
      "\n",
      "\n",
      "# C. Get probability estimation on x\n",
      "# INPUT:\n",
      "#     x: features\n",
      "#     w: weights\n",
      "# OUTPUT:\n",
      "#     probability of p(y = 1 | x; w)\n",
      "def predict(x, w):\n",
      "    wTx = 0.\n",
      "    for i in x:  # do wTx\n",
      "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
      "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid\n",
      "\n",
      "\n",
      "# D. Update given model\n",
      "# INPUT:\n",
      "# alpha: learning rate\n",
      "#     w: weights\n",
      "#     n: sum of previous absolute gradients for a given feature\n",
      "#        this is used for adaptive learning rate\n",
      "#     x: feature, a list of indices\n",
      "#     p: prediction of our model\n",
      "#     y: answer\n",
      "# MODIFIES:\n",
      "#     w: weights\n",
      "#     n: sum of past absolute gradients\n",
      "def update(alpha, w, n, x, p, y):\n",
      "    for i in x:\n",
      "        # alpha / sqrt(n) is the adaptive learning rate\n",
      "        # (p - y) * x[i] is the current gradient\n",
      "        # note that in our case, if i in x then x[i] = 1.\n",
      "        n[i] += abs(p - y)\n",
      "        w[i] -= (p - y) * 1. * alpha / sqrt(n[i])\n",
      "\n",
      "\n",
      "# training and testing #######################################################\n",
      "start = datetime.now()\n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = [k for k in range(33) if k != 13]\n",
      "\n",
      "# initialize our model, all 32 of them, again ignoring y14\n",
      "w = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "n = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "\n",
      "loss = 0.\n",
      "loss_y14 = log(1. - 10**-15)\n",
      "\n",
      "for ID, x, y in data(train, label):\n",
      "\n",
      "    # get predictions and train on all labels\n",
      "    for k in K:\n",
      "        p = predict(x, w[k])\n",
      "        update(alpha, w[k], n[k], x, p, y[k])\n",
      "        loss += logloss(p, y[k])  # for progressive validation\n",
      "    loss += loss_y14  # the loss of y14, logloss is never zero\n",
      "\n",
      "    # print out progress, so that we know everything is working\n",
      "    if ID % 100000 == 0:\n",
      "        print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
      "            datetime.now(), ID, (loss/33.)/ID))\n",
      "\n",
      "with open('./submission1234_corr.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    for ID, x in data(test):\n",
      "        for k in K:\n",
      "            p = predict(x, w[k])\n",
      "            outfile.write('%s_y%d,%s\\n' % (ID, k+1, str(p)))\n",
      "            if k == 12:\n",
      "                outfile.write('%s_y14,0.0\\n' % ID)\n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2014-10-21 12:29:40.835000\tencountered: 100000\tcurrent logloss: 0.023806\n",
        "2014-10-21 19:51:38.817000\tencountered: 200000\tcurrent logloss: 0.019913"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 20:01:50.973000\tencountered: 300000\tcurrent logloss: 0.017911"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 20:11:59.193000\tencountered: 400000\tcurrent logloss: 0.016660"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 20:22:05.678000\tencountered: 500000\tcurrent logloss: 0.015701"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 20:32:12.491000\tencountered: 600000\tcurrent logloss: 0.015001"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 20:42:21.016000\tencountered: 700000\tcurrent logloss: 0.014465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 20:52:32.917000\tencountered: 800000\tcurrent logloss: 0.013996"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 21:02:45.291000\tencountered: 900000\tcurrent logloss: 0.013599"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 21:12:55.953000\tencountered: 1000000\tcurrent logloss: 0.013254"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 21:23:10.853000\tencountered: 1100000\tcurrent logloss: 0.012947"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 21:33:27.133000\tencountered: 1200000\tcurrent logloss: 0.012683"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 21:44:01.558000\tencountered: 1300000\tcurrent logloss: 0.012444"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 21:54:21.617000\tencountered: 1400000\tcurrent logloss: 0.012235"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 22:04:43.557000\tencountered: 1500000\tcurrent logloss: 0.012040"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 22:15:18.956000\tencountered: 1600000\tcurrent logloss: 0.011859"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-10-21 22:25:45.730000\tencountered: 1700000\tcurrent logloss: 0.011692"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done, elapsed time: 10:19:33.311000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd '../Kaggle/Trade Shift/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\SYan\\Desktop\\Kaggle\\Trade Shift\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "                   Version 2, December 2004\n",
      "\n",
      "Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n",
      "\n",
      "Everyone is permitted to copy and distribute verbatim or modified\n",
      "copies of this license document, and changing it is allowed as long\n",
      "as the name is changed.\n",
      "\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "  TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n",
      "\n",
      " 0. You just DO WHAT THE FUCK YOU WANT TO.\n",
      "'''\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "from math import log, exp, sqrt\n",
      "\n",
      "\n",
      "# TL; DR\n",
      "# the main learning process start at line 122\n",
      "\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "train = 'train.csv'  # path to training file\n",
      "label = 'trainLabels.csv'  # path to label file of training data\n",
      "test = 'test.csv'  # path to testing file\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "# A. x, y generator\n",
      "# INPUT:\n",
      "#     path: path to train.csv or test.csv\n",
      "#     label_path: (optional) path to trainLabels.csv\n",
      "# YIELDS:\n",
      "#     ID: id of the instance (can also acts as instance count)\n",
      "#     x: a list of indices that its value is 1\n",
      "#     y: (if label_path is present) label value of y1 to y33\n",
      "def data(path, label_path=None):\n",
      "    for t, line in enumerate(open(path)):\n",
      "        if t > 10000:\n",
      "            break\n",
      "        \n",
      "        # initialize our generator\n",
      "        if t == 0:\n",
      "            # create a static x,\n",
      "            # so we don't have to construct a new x for every instance\n",
      "            x = [0] * 146\n",
      "            if label_path:\n",
      "                label = open(label_path)\n",
      "                label.readline()  # we don't need the headers\n",
      "            continue\n",
      "        # parse x\n",
      "        for m, feat in enumerate(line.rstrip().split(',')):\n",
      "            if m == 0:\n",
      "                ID = int(feat)\n",
      "            else:\n",
      "                # one-hot encode everything with hash trick\n",
      "                # categorical: one-hotted\n",
      "                # boolean: ONE-HOTTED\n",
      "                # numerical: ONE-HOTTED!\n",
      "                # note, the build in hash(), although fast is not stable,\n",
      "                #       i.e., same value won't always have the same hash\n",
      "                #       on different machines\n",
      "                x[m] = abs(hash(str(m) + '_' + feat)) % D\n",
      "        # parse y, if provided\n",
      "        if label_path:\n",
      "            # use float() to prevent future type casting, [1:] to ignore id\n",
      "            y = [float(y) for y in label.readline().split(',')[1:]]\n",
      "        yield (ID, x, y) if label_path else (ID, x)\n",
      "\n",
      "\n",
      "# B. Bounded logloss\n",
      "# INPUT:\n",
      "#     p: our prediction\n",
      "#     y: real answer\n",
      "# OUTPUT\n",
      "#     bounded logarithmic loss of p given y\n",
      "def logloss(p, y):\n",
      "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
      "    return -log(p) if y == 1. else -log(1. - p)\n",
      "\n",
      "\n",
      "# C. Get probability estimation on x\n",
      "# INPUT:\n",
      "#     x: features\n",
      "#     w: weights\n",
      "# OUTPUT:\n",
      "#     probability of p(y = 1 | x; w)\n",
      "def predict(x, w):\n",
      "    wTx = 0.\n",
      "    for i in x:  # do wTx\n",
      "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
      "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid\n",
      "\n",
      "\n",
      "# D. Update given model\n",
      "# INPUT:\n",
      "# alpha: learning rate\n",
      "#     w: weights\n",
      "#     n: sum of previous absolute gradients for a given feature\n",
      "#        this is used for adaptive learning rate\n",
      "#     x: feature, a list of indices\n",
      "#     p: prediction of our model\n",
      "#     y: answer\n",
      "# MODIFIES:\n",
      "#     w: weights\n",
      "#     n: sum of past absolute gradients\n",
      "def update(alpha, w, n, x, p, y):\n",
      "    for i in x:\n",
      "        # alpha / sqrt(n) is the adaptive learning rate\n",
      "        # (p - y) * x[i] is the current gradient\n",
      "        # note that in our case, if i in x then x[i] = 1.\n",
      "        n[i] += abs(p - y)\n",
      "        w[i] -= (p - y) * 1. * alpha / sqrt(n[i])\n",
      "\n",
      "\n",
      "# training and testing #######################################################\n",
      "start = datetime.now()\n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = [k for k in range(33) if k != 13]\n",
      "\n",
      "# initialize our model, all 32 of them, again ignoring y14\n",
      "w = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "n = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "\n",
      "loss = 0.\n",
      "loss_y14 = log(1. - 10**-15)\n",
      "\n",
      "for ID, x, y in data(train, label):\n",
      "\n",
      "    # get predictions and train on all labels\n",
      "    for k in K:\n",
      "        p = predict(x, w[k])\n",
      "        update(alpha, w[k], n[k], x, p, y[k])\n",
      "        loss += logloss(p, y[k])  # for progressive validation\n",
      "    loss += loss_y14  # the loss of y14, logloss is never zero\n",
      "\n",
      "    # print out progress, so that we know everything is working\n",
      "    if ID % 100000 == 0:\n",
      "        print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
      "            datetime.now(), ID, (loss/33.)/ID))\n",
      "\n",
      "with open('./submission1234.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    for ID, x in data(test):\n",
      "        for k in K:\n",
      "            p = predict(x, w[k])\n",
      "            outfile.write('%s_y%d,%s\\n' % (ID, k+1, str(p)))\n",
      "            if k == 12:\n",
      "                outfile.write('%s_y14,0.0\\n' % ID)\n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "                   Version 2, December 2004\n",
      "\n",
      "Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n",
      "\n",
      "Everyone is permitted to copy and distribute verbatim or modified\n",
      "copies of this license document, and changing it is allowed as long\n",
      "as the name is changed.\n",
      "\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "  TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n",
      "\n",
      " 0. You just DO WHAT THE FUCK YOU WANT TO.\n",
      "'''\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "from math import log, exp, sqrt\n",
      "\n",
      "\n",
      "# TL; DR\n",
      "# the main learning process start at line 122\n",
      "\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "train = 'train.csv'  # path to training file\n",
      "label = 'trainLabels.csv'  # path to label file of training data\n",
      "test = 'test.csv'  # path to testing file\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "# A. x, y generator\n",
      "# INPUT:\n",
      "#     path: path to train.csv or test.csv\n",
      "#     label_path: (optional) path to trainLabels.csv\n",
      "# YIELDS:\n",
      "#     ID: id of the instance (can also acts as instance count)\n",
      "#     x: a list of indices that its value is 1\n",
      "#     y: (if label_path is present) label value of y1 to y33\n",
      "def data(path, label_path=None):\n",
      "    for t, line in enumerate(open(path)):\n",
      "        if t > 1000:\n",
      "            break\n",
      "        \n",
      "        # initialize our generator\n",
      "        if t == 0:\n",
      "            # create a static x,\n",
      "            # so we don't have to construct a new x for every instance\n",
      "            x = [0] * (146 + 46)\n",
      "            if label_path:\n",
      "                label = open(label_path)\n",
      "                label.readline()  # we don't need the headers\n",
      "            continue\n",
      "        # parse x\n",
      "        for m, feat in enumerate(line.rstrip().split(',')):\n",
      "            if m == 0:\n",
      "                ID = int(feat)\n",
      "            else:\n",
      "                # one-hot encode everything with hash trick\n",
      "                # categorical: one-hotted\n",
      "                # boolean: ONE-HOTTED\n",
      "                # numerical: ONE-HOTTED!\n",
      "                # note, the build in hash(), although fast is not stable,\n",
      "                #       i.e., same value won't always have the same hash\n",
      "                #       on different machines\n",
      "                x[m] = abs(hash(str(m) + '_' + feat)) % D\n",
      "        \n",
      "        row  = line.rstrip().split(',')\n",
      "        hash_cols = [3,4,34,35,61,64,65,91,94,95]\n",
      "        t = 146\n",
      "        for i in xrange(10):\n",
      "          for j in xrange(i+1, 10):\n",
      "            t += 1\n",
      "            x[t] = abs(hash(row[hash_cols[i]]+\"_x_\"+row[hash_cols[j]])) % D\n",
      "        # parse y, if provided\n",
      "        if label_path:\n",
      "            # use float() to prevent future type casting, [1:] to ignore id\n",
      "            y = [float(y) for y in label.readline().split(',')[1:]]\n",
      "        yield (ID, x, y) if label_path else (ID, x)\n",
      "\n",
      "\n",
      "# B. Bounded logloss\n",
      "# INPUT:\n",
      "#     p: our prediction\n",
      "#     y: real answer\n",
      "# OUTPUT\n",
      "#     bounded logarithmic loss of p given y\n",
      "def logloss(p, y):\n",
      "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
      "    return -log(p) if y == 1. else -log(1. - p)\n",
      "\n",
      "\n",
      "# C. Get probability estimation on x\n",
      "# INPUT:\n",
      "#     x: features\n",
      "#     w: weights\n",
      "# OUTPUT:\n",
      "#     probability of p(y = 1 | x; w)\n",
      "def predict(x, w):\n",
      "    wTx = 0.\n",
      "    for i in x:  # do wTx\n",
      "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
      "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid\n",
      "\n",
      "\n",
      "# D. Update given model\n",
      "# INPUT:\n",
      "# alpha: learning rate\n",
      "#     w: weights\n",
      "#     n: sum of previous absolute gradients for a given feature\n",
      "#        this is used for adaptive learning rate\n",
      "#     x: feature, a list of indices\n",
      "#     p: prediction of our model\n",
      "#     y: answer\n",
      "# MODIFIES:\n",
      "#     w: weights\n",
      "#     n: sum of past absolute gradients\n",
      "def update(alpha, w, n, x, p, y):\n",
      "    for i in x:\n",
      "        # alpha / sqrt(n) is the adaptive learning rate\n",
      "        # (p - y) * x[i] is the current gradient\n",
      "        # note that in our case, if i in x then x[i] = 1.\n",
      "        n[i] += abs(p - y)\n",
      "        w[i] -= (p - y) * 1. * alpha / sqrt(n[i])\n",
      "\n",
      "\n",
      "# training and testing #######################################################\n",
      "start = datetime.now()\n",
      "\n",
      "import csv\n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = [k for k in range(33) if k != 13]\n",
      "\n",
      "# initialize our model, all 32 of them, again ignoring y14\n",
      "w = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "n = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "\n",
      "loss = 0.\n",
      "loss_y14 = log(1. - 10**-15)\n",
      "\n",
      "with open('./hashing_train.csv', 'w') as outfile:\n",
      "    for ID, x, y in data(train, label):\n",
      "        writer = csv.writer(outfile)\n",
      "        writer.writerow(x)\n",
      "\n",
      "    # print out progress, so that we know everything is working\n",
      "    if ID % 100 == 0:\n",
      "        print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
      "            datetime.now(), ID, (loss/33.)/ID))\n",
      "\n",
      "'''\n",
      "with open('./submission1234.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    for ID, x in data(test):\n",
      "        for k in K:\n",
      "            p = predict(x, w[k])\n",
      "            outfile.write('%s_y%d,%s\\n' % (ID, k+1, str(p)))\n",
      "            if k == 12:\n",
      "                outfile.write('%s_y14,0.0\\n' % ID)\n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "\"\\nwith open('./submission1234.csv', 'w') as outfile:\\n    outfile.write('id_label,pred\\n')\\n    for ID, x in data(test):\\n        for k in K:\\n            p = predict(x, w[k])\\n            outfile.write('%s_y%d,%s\\n' % (ID, k+1, str(p)))\\n            if k == 12:\\n                outfile.write('%s_y14,0.0\\n' % ID)\\n\\nprint('Done, elapsed time: %s' % str(datetime.now() - start))\\n\""
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 49,
       "text": [
        "[0,\n",
        " 154635,\n",
        " 208524,\n",
        " 178917,\n",
        " 94673,\n",
        " 44373,\n",
        " 204412,\n",
        " 49764,\n",
        " 253078,\n",
        " 161027,\n",
        " 235890,\n",
        " 185563,\n",
        " 208915,\n",
        " 234669,\n",
        " 32218,\n",
        " 164116,\n",
        " 80588,\n",
        " 62162,\n",
        " 62039,\n",
        " 260966,\n",
        " 169869,\n",
        " 26229,\n",
        " 6350,\n",
        " 149751,\n",
        " 128027,\n",
        " 184398,\n",
        " 84755,\n",
        " 181823,\n",
        " 239003,\n",
        " 240738,\n",
        " 79316,\n",
        " 251707,\n",
        " 77130,\n",
        " 38797,\n",
        " 202510,\n",
        " 22739,\n",
        " 115200,\n",
        " 251211,\n",
        " 166655,\n",
        " 162167,\n",
        " 93659,\n",
        " 232488,\n",
        " 203353,\n",
        " 255373,\n",
        " 66821,\n",
        " 227052,\n",
        " 256704,\n",
        " 19823,\n",
        " 131556,\n",
        " 13155,\n",
        " 33239,\n",
        " 94517,\n",
        " 89923,\n",
        " 1802,\n",
        " 171799,\n",
        " 121843,\n",
        " 239956,\n",
        " 91067,\n",
        " 94646,\n",
        " 152408,\n",
        " 219654,\n",
        " 238052,\n",
        " 13373,\n",
        " 198292,\n",
        " 182071,\n",
        " 129042,\n",
        " 219919,\n",
        " 21932,\n",
        " 101062,\n",
        " 17314,\n",
        " 68200,\n",
        " 45633,\n",
        " 1738,\n",
        " 193832,\n",
        " 167852,\n",
        " 43907,\n",
        " 211379,\n",
        " 196060,\n",
        " 125019,\n",
        " 120558,\n",
        " 241760,\n",
        " 240184,\n",
        " 17478,\n",
        " 257173,\n",
        " 90338,\n",
        " 142840,\n",
        " 143863,\n",
        " 168658,\n",
        " 144825,\n",
        " 170789,\n",
        " 185628,\n",
        " 139623,\n",
        " 183319,\n",
        " 232020,\n",
        " 153985,\n",
        " 202694,\n",
        " 208596,\n",
        " 58005,\n",
        " 81402,\n",
        " 225137,\n",
        " 160631,\n",
        " 239827,\n",
        " 93962,\n",
        " 142677,\n",
        " 258956,\n",
        " 45519,\n",
        " 4941,\n",
        " 454,\n",
        " 105969,\n",
        " 224376,\n",
        " 87902,\n",
        " 55867,\n",
        " 190116,\n",
        " 194603,\n",
        " 194894,\n",
        " 34338,\n",
        " 180203,\n",
        " 131496,\n",
        " 206970,\n",
        " 88563,\n",
        " 21767,\n",
        " 161004,\n",
        " 117391,\n",
        " 261127,\n",
        " 260997,\n",
        " 162626,\n",
        " 190589,\n",
        " 240836,\n",
        " 98368,\n",
        " 214146,\n",
        " 202048,\n",
        " 67438,\n",
        " 158693,\n",
        " 32946,\n",
        " 151333,\n",
        " 221940,\n",
        " 213026,\n",
        " 94650,\n",
        " 16115,\n",
        " 192982,\n",
        " 72077,\n",
        " 139692,\n",
        " 41351,\n",
        " 199890,\n",
        " 167670,\n",
        " 4680]"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load hashing_feature_new.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "#\"\"\"\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0, nrows = 10000)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0, nrows = 10000)\n",
      "raw_test = pd.read_csv('test.csv', header=0, nrows = 10000)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 10000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "test = raw_test\n",
      "\n",
      "del raw_test\n",
      "del raw_train\n",
      "del raw_label\n",
      "\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v, table):\n",
      "    for key in v:\n",
      "        if not key in table or key == 'YES':\n",
      "            table[key] = 1\n",
      "        elif key == 'NO':\n",
      "            table[key] = 0\n",
      "        elif key == '' or key == '-999':\n",
      "            table[key] = -999\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        if key in hashT:\n",
      "            v[ind[count]] = hashT[key]\n",
      "        else:\n",
      "            v[ind[count]] = 0\n",
      "        count = count + 1\n",
      "    return v\n",
      "\n",
      "\n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "train = train.fillna('-999')\n",
      "test = test.fillna('-999')\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        table = freq(train[i], table)\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        train[i] = lookup(table, train[i])\n",
      "\ttest[i] = lookup(table, test[i])\n",
      "\n",
      "# Split the train into training and validation\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows]\n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "# scaling    \n",
      "#train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "#validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "#test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "\n",
      "del table\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "# Model training ###################################################\n",
      "        \n",
      "print \"Step3: Start training models\"       \n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = set(label)\n",
      "count = 0\n",
      "model = {}\n",
      "log_loss = {}\n",
      "\n",
      "for k in K:\n",
      "    if k != 'y14' and  k != 'id':\n",
      "        forest = RandomForestClassifier(n_estimators = 10, criterion = \"gini\", verbose = 0, n_jobs = 1)\n",
      "       # No 'y14' or 'id'    \n",
      "        model[k] = forest.fit(train.drop('id', 1), label[k])\n",
      "        output_validation = model[k].predict_proba(validation.drop('id', 1))\n",
      "        log_loss[k] = metrics.log_loss(label_validation[k].as_matrix(), output_validation)\n",
      "        #print \"\\n\", k, \"AUC = \", metrics.roc_auc_score(label_validation[k], output_validation[:,1])\n",
      "        print \"\\n\", k, \"Log_Loss = \", log_loss[k]\n",
      "        count += 1\n",
      "\n",
      "print('\\nTotal Log Loss = ', sum(log_loss.values()) / 33, '\\n')\n",
      "p2 = datetime.now()\n",
      "print('Training is done, elapsed time: %s' % str(p2 - p1))\n",
      "\n",
      "# Saving submission #######################################################################\n",
      "\n",
      "with open('./submission_new.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(test))\n",
      "    #n = range(100)\n",
      "\n",
      "    K = range(33)\n",
      "    for k in K:\n",
      "        key = 'y' + str(k + 1)\n",
      "        if k != 13:\n",
      "            output[key] = model[key].predict_proba(test.drop('id', 1))\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 100000 == 0:\n",
      "            print i\n",
      "        for k in K:\n",
      "            key = 'y' + str(k + 1) \n",
      "            if k == 13:\n",
      "                outfile.write('%s_y14,0.0\\n' % test.id[i])\n",
      "            else:\n",
      "                outfile.write('%s_%s,%s\\n' % (test.id[i], key, str(output[key][i,1])))\n",
      "    \n",
      "print('Dumping is done, elapsed time: %s' % str(datetime.now() - p2))           \n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "blend_1 = pd.read_csv('submission1234.csv')\n",
      "blend_2 = pd.read_csv('submission1234_corr.csv')\n",
      "blend_3 = pd.read_csv('submission_new.csv')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "#blend_1 = pd.read_csv('submission1234.csv')\n",
      "#blend_2 = pd.read_csv('submission1234_corr.csv')\n",
      "#blend_3 = pd.read_csv('submission_new.csv')\n",
      "\n",
      "start = datetime.now()\n",
      "prob = 0.4 * blend_1.pred + 0.6 * blend_2.pred\n",
      "id_label = blend_1.id_label\n",
      "\n",
      "with open('./submission_blen_2.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    output = {}\n",
      "    n = range(len(blend_1))\n",
      "    #n = range(100)\n",
      "                     \n",
      "    for i in n:\n",
      "        if i % 1000000 == 0:\n",
      "            print i\n",
      "        \n",
      "        outfile.write('%s,%s\\n' % (id_label[i], prob[i])) \n",
      "        \n",
      "print \"It takes time = \", datetime.now() - start"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "3000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "4000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "5000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "6000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "8000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "9000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "10000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "11000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "12000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "13000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "14000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "15000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "16000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "17000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "It takes time = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0:23:13.884000\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd 'Trade Shift/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\SYan\\Desktop\\Kaggle\\Trade Shift\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "#\"\"\"\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0, nrows = 10000)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0, nrows = 10000)\n",
      "raw_test = pd.read_csv('test.csv', header=0, nrows = 10000)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "#\"\"\"\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 10000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "test = raw_test\n",
      "\n",
      "del raw_test\n",
      "del raw_train\n",
      "del raw_label\n",
      "\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v, table):\n",
      "    for key in v:\n",
      "        if not key in table or key == 'YES':\n",
      "            table[key] = 1\n",
      "        elif key == 'NO':\n",
      "            table[key] = 0\n",
      "        elif key == '' or key == '-999':\n",
      "            table[key] = -999\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        if key in hashT:\n",
      "            v[ind[count]] = hashT[key]\n",
      "        else:\n",
      "            v[ind[count]] = 0\n",
      "        count = count + 1\n",
      "    return v\n",
      "  \n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "train = train.fillna('-999')\n",
      "test = test.fillna('-999')\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        table = freq(train[i], table)\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        train[i] = lookup(table, train[i])\n",
      "        test[i] = lookup(table, test[i])\n",
      "      \n",
      "print \"Starting Log Conversion\"\n",
      "# We convert the frequency into log scale and create pair-correlation\n",
      "hash_cols = [3,4,34,35,61,64,65,91,94,95] # This one supposed have high correlation\n",
      "for i in range(10):\n",
      "    key = 'x' + str(hash_cols[i])\n",
      "    vec = pd.DataFrame(np.zeros(train.shape[0]), columns= ['log' + key])\n",
      "    print key, vec.shape, train.shape\n",
      "    for j in range(len(train)):\n",
      "        num = train[key][train.index[j]]\n",
      "        if num != -999.0:\n",
      "            vec['log' + key][j] = np.log(1.0 + num)\n",
      "    \n",
      "    train = pd.concat([train,vec], axis=1)\n",
      "\n",
      "\n",
      "for i in range(10):\n",
      "    key1 = 'logx' + str(hash_cols[i])\n",
      "    for j in range(i+1, 10):\n",
      "        key2 = 'logx' + str(hash_cols[j])\n",
      "        print \"corr = \", key1, key2\n",
      "        vec = pd.DataFrame(train[key1] * train[key2], columns=[key1 + key2])\n",
      "        train = pd.concat([train, vec], axis = 1)\n",
      "\n",
      "# Split the train into training and validation\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows]\n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "# scaling    \n",
      "#train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "#validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "#test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "\n",
      "del table\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step0: Loading raw data\n",
        "Data loading is done! elapsed time: 0:00:00.605000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step1: Sampling\n",
        "Step2: Hashing Frequency Table\n",
        "Starting Log Conversion"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "x3 (10000, 1) (10000, 146)\n",
        "x4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 147)\n",
        "x34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 148)\n",
        "x35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 149)\n",
        "x61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 150)\n",
        "x64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 151)\n",
        "x65"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 152)\n",
        "x91"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 153)\n",
        "x94"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 154)\n",
        "x95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (10000, 1) (10000, 155)\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx4\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx34\n",
        "corr =  logx3 logx35\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx61\n",
        "corr =  logx3 logx64\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx65\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx3 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx34\n",
        "corr =  logx4 logx35\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx61\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx64\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx65\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx4 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx35\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx61\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx64\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx65\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx34 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx35 logx61\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx35 logx64\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx35 logx65\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx35 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx35 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx35 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx61 logx64\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx61 logx65\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx61 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx61 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx61 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx64 logx65\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx64 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx64 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx64 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx65 logx91\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx65 logx94\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx65 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx91 logx94\n",
        "corr =  logx91 logx95\n",
        "corr = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " logx94 logx95\n",
        "Sampling and hashing are done, elapsed time: 0:00:17.482000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.logx34logx35"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "4621    13.951647\n",
        "5519    24.727585\n",
        "6470     9.482236\n",
        "6822     6.438493\n",
        "5438    22.081124\n",
        "8309     6.656627\n",
        "2459    19.401860\n",
        "7282     3.131822\n",
        "4563     4.083777\n",
        "1378     6.899720\n",
        "9926    13.799440\n",
        "8341     8.186570\n",
        "5447    16.607704\n",
        "6361    23.016935\n",
        "6905     2.849441\n",
        "...\n",
        "3093     4.820588\n",
        "7471     1.115577\n",
        "3995     2.284500\n",
        "2801     9.641177\n",
        "3265     4.402505\n",
        "1120     9.641177\n",
        "7680     7.351942\n",
        "3326    39.776637\n",
        "445      9.871499\n",
        "4132    13.210936\n",
        "3563    24.726162\n",
        "9039    23.089175\n",
        "2661    19.669712\n",
        "7118    25.146117\n",
        "2779    25.994142\n",
        "Name: logx34logx35, Length: 8000, dtype: float64"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.logx34"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "4621    2.302585\n",
        "5519    3.610918\n",
        "6470    1.609438\n",
        "6822    1.386294\n",
        "5438    2.995732\n",
        "8309    1.098612\n",
        "2459    2.833213\n",
        "7282    1.609438\n",
        "4563    0.693147\n",
        "1378    1.098612\n",
        "9926    2.197225\n",
        "8341    1.386294\n",
        "5447    3.178054\n",
        "6361    3.555348\n",
        "6905    0.693147\n",
        "...\n",
        "3093    0.693147\n",
        "7471    0.693147\n",
        "3995    0.693147\n",
        "2801    1.386294\n",
        "3265    1.098612\n",
        "1120    1.386294\n",
        "7680    1.386294\n",
        "3326    5.153292\n",
        "445     1.791759\n",
        "4132    2.397895\n",
        "3563    3.555348\n",
        "9039    3.637586\n",
        "2661    3.583519\n",
        "7118    3.688879\n",
        "2779    3.737670\n",
        "Name: logx34, Length: 8000, dtype: float64"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train.logx35"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 88,
       "text": [
        "4621    6.059123\n",
        "5519    6.848005\n",
        "6470    5.891644\n",
        "6822    4.644391\n",
        "5438    7.370860\n",
        "8309    6.059123\n",
        "2459    6.848005\n",
        "7282    1.945910\n",
        "4563    5.891644\n",
        "1378    6.280396\n",
        "9926    6.280396\n",
        "8341    5.905362\n",
        "5447    5.225747\n",
        "6361    6.473891\n",
        "6905    4.110874\n",
        "...\n",
        "3093    6.954639\n",
        "7471    1.609438\n",
        "3995    3.295837\n",
        "2801    6.954639\n",
        "3265    4.007333\n",
        "1120    6.954639\n",
        "7680    5.303305\n",
        "3326    7.718685\n",
        "445     5.509388\n",
        "4132    5.509388\n",
        "3563    6.954639\n",
        "9039    6.347389\n",
        "2661    5.488938\n",
        "7118    6.816736\n",
        "2779    6.954639\n",
        "Name: logx35, Length: 8000, dtype: float64"
       ]
      }
     ],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load fast_solution.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "                   Version 2, December 2004\n",
      "\n",
      "Copyright (C) 2004 Sam Hocevar <sam@hocevar.net>\n",
      "\n",
      "Everyone is permitted to copy and distribute verbatim or modified\n",
      "copies of this license document, and changing it is allowed as long\n",
      "as the name is changed.\n",
      "\n",
      "           DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE\n",
      "  TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION\n",
      "\n",
      " 0. You just DO WHAT THE FUCK YOU WANT TO.\n",
      "'''\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "from math import log, exp, sqrt\n",
      "\n",
      "\n",
      "# TL; DR\n",
      "# the main learning process start at line 122\n",
      "\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "train = 'train.csv'  # path to training file\n",
      "label = 'trainLabels.csv'  # path to label file of training data\n",
      "test = 'test.csv'  # path to testing file\n",
      "\n",
      "D = 2 ** 23  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "# A. x, y generator\n",
      "# INPUT:\n",
      "#     path: path to train.csv or test.csv\n",
      "#     label_path: (optional) path to trainLabels.csv\n",
      "# YIELDS:\n",
      "#     ID: id of the instance (can also acts as instance count)\n",
      "#     x: a list of indices that its value is 1\n",
      "#     y: (if label_path is present) label value of y1 to y33\n",
      "def data(path, label_path=None):\n",
      "    for t, line in enumerate(open(path)):\n",
      "        #if t > 100000:\n",
      "         #   break\n",
      "        \n",
      "        # initialize our generator\n",
      "        if t == 0:\n",
      "            # create a static x,\n",
      "            # so we don't have to construct a new x for every instance\n",
      "            x = [0] * (146 + 46)\n",
      "            if label_path:\n",
      "                label = open(label_path)\n",
      "                label.readline()  # we don't need the headers\n",
      "            continue\n",
      "        # parse x\n",
      "        for m, feat in enumerate(line.rstrip().split(',')):\n",
      "            if m == 0:\n",
      "                ID = int(feat)\n",
      "            else:\n",
      "                # one-hot encode everything with hash trick\n",
      "                # categorical: one-hotted\n",
      "                # boolean: ONE-HOTTED\n",
      "                # numerical: ONE-HOTTED!\n",
      "                # note, the build in hash(), although fast is not stable,\n",
      "                #       i.e., same value won't always have the same hash\n",
      "                #       on different machines\n",
      "                x[m] = abs(hash(str(m) + '_' + feat)) % D\n",
      "        \n",
      "\trow = line.rstrip().split(',')\n",
      "\thash_cols = [3,4,34,35,61,64,65,91,94,95]\n",
      "        t = 146\n",
      "        for i in xrange(10):\n",
      "          for j in xrange(i+1, 10):\n",
      "            t += 1\n",
      "            x[t] = abs(hash(row[hash_cols[i]]+\"_x_\"+row[hash_cols[j]])) % D\n",
      "\n",
      "# parse y, if provided\n",
      "        if label_path:\n",
      "            # use float() to prevent future type casting, [1:] to ignore id\n",
      "            y = [float(y) for y in label.readline().split(',')[1:]]\n",
      "        yield (ID, x, y) if label_path else (ID, x)\n",
      "\n",
      "\n",
      "# B. Bounded logloss\n",
      "# INPUT:\n",
      "#     p: our prediction\n",
      "#     y: real answer\n",
      "# OUTPUT\n",
      "#     bounded logarithmic loss of p given y\n",
      "def logloss(p, y):\n",
      "    p = max(min(p, 1. - 10e-15), 10e-15)\n",
      "    return -log(p) if y == 1. else -log(1. - p)\n",
      "\n",
      "\n",
      "# C. Get probability estimation on x\n",
      "# INPUT:\n",
      "#     x: features\n",
      "#     w: weights\n",
      "# OUTPUT:\n",
      "#     probability of p(y = 1 | x; w)\n",
      "def predict(x, w):\n",
      "    wTx = 0.\n",
      "    for i in x:  # do wTx\n",
      "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
      "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid\n",
      "\n",
      "\n",
      "# D. Update given model\n",
      "# INPUT:\n",
      "# alpha: learning rate\n",
      "#     w: weights\n",
      "#     n: sum of previous absolute gradients for a given feature\n",
      "#        this is used for adaptive learning rate\n",
      "#     x: feature, a list of indices\n",
      "#     p: prediction of our model\n",
      "#     y: answer\n",
      "# MODIFIES:\n",
      "#     w: weights\n",
      "#     n: sum of past absolute gradients\n",
      "def update(alpha, w, n, x, p, y):\n",
      "    for i in x:\n",
      "        # alpha / sqrt(n) is the adaptive learning rate\n",
      "        # (p - y) * x[i] is the current gradient\n",
      "        # note that in our case, if i in x then x[i] = 1.\n",
      "        n[i] += abs(p - y)\n",
      "        w[i] -= (p - y) * 1. * alpha / sqrt(n[i])\n",
      "\n",
      "\n",
      "# training and testing #######################################################\n",
      "start = datetime.now()\n",
      "\n",
      "# a list for range(0, 33) - 13, no need to learn y14 since it is always 0\n",
      "K = [k for k in range(33) if k != 13]\n",
      "\n",
      "# initialize our model, all 32 of them, again ignoring y14\n",
      "w = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "n = [[0.] * D if k != 13 else None for k in range(33)]\n",
      "\n",
      "loss = 0.\n",
      "loss_y14 = log(1. - 10**-15)\n",
      "\n",
      "for ID, x, y in data(train, label):\n",
      "\n",
      "    # get predictions and train on all labels\n",
      "    for k in K:\n",
      "        p = predict(x, w[k])\n",
      "        update(alpha, w[k], n[k], x, p, y[k])\n",
      "        loss += logloss(p, y[k])  # for progressive validation\n",
      "    loss += loss_y14  # the loss of y14, logloss is never zero\n",
      "\n",
      "    # print out progress, so that we know everything is working\n",
      "    if ID % 100000 == 0:\n",
      "        print('%s\\tencountered: %d\\tcurrent logloss: %f' % (\n",
      "            datetime.now(), ID, (loss/33.)/ID))\n",
      "\n",
      "with open('./submission_bit24.csv', 'w') as outfile:\n",
      "    outfile.write('id_label,pred\\n')\n",
      "    for ID, x in data(test):\n",
      "        for k in K:\n",
      "            p = predict(x, w[k])\n",
      "            outfile.write('%s_y%d,%s\\n' % (ID, k+1, str(p)))\n",
      "            if k == 12:\n",
      "                outfile.write('%s_y14,0.0\\n' % ID)\n",
      "\n",
      "print('Done, elapsed time: %s' % str(datetime.now() - start))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load log_corr.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Created on Mon Oct 13 13:40:21 2014\n",
      "\n",
      "@author: SYan\n",
      "\"\"\"\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import random\n",
      "\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import preprocessing\n",
      "from sklearn import metrics\n",
      "\n",
      "# parameters #################################################################\n",
      "\n",
      "start = datetime.now()\n",
      "\n",
      "\n",
      "# Only loading one time\n",
      "print \"Step0: Loading raw data\"\n",
      "raw_train = pd.read_csv('train.csv', header=0)\n",
      "raw_label = pd.read_csv('trainLabels.csv', header=0)\n",
      "raw_test = pd.read_csv('test.csv', header=0)\n",
      "\n",
      "print('Data loading is done! elapsed time: %s' % str(datetime.now() - start))\n",
      "\n",
      "#train = pd.read_csv('train_vec.csv', header=0, nrows=10000)\n",
      "#validation = pd.read_csv('validation_vec.csv', header=0, nrows=10000)\n",
      "#test = pd.read_csv('test_vec.csv', header=0, nrows=10000)\n",
      "\n",
      "\n",
      "print \"Step1: Sampling\"\n",
      "nSample = 100000\n",
      "rows = random.sample(raw_train.index, nSample)\n",
      "train = raw_train.ix[rows]\n",
      "label = raw_label.ix[rows]\n",
      "test = raw_test\n",
      "\n",
      "del raw_test\n",
      "del raw_train\n",
      "del raw_label\n",
      "\n",
      "\n",
      "D = 2 ** 18  # number of weights use for each model, we have 32 of them\n",
      "alpha = .1   # learning rate for sgd optimization\n",
      "\n",
      "#train = train.append(label)\n",
      "#train.dropna()\n",
      "\n",
      "# function, generator definitions ############################################\n",
      "\n",
      "#     bounded logarithmic loss of p given y\n",
      "def freq(v, table):\n",
      "    for key in v:\n",
      "        if not key in table or key == 'YES':\n",
      "            table[key] = 1\n",
      "        elif key == 'NO':\n",
      "            table[key] = 0\n",
      "        elif key == '' or key == '-999':\n",
      "            table[key] = -999\n",
      "        else:\n",
      "            table[key] += 1\n",
      "        \n",
      "    return table\n",
      "    \n",
      "\n",
      "def lookup(hashT, v):\n",
      "    ind = v.index\n",
      "    count = 0\n",
      "    \n",
      "    for key in v:\n",
      "        if key in hashT:\n",
      "            v[ind[count]] = hashT[key]\n",
      "        else:\n",
      "            v[ind[count]] = 0\n",
      "        count = count + 1\n",
      "    return v\n",
      "  \n",
      "#hasher = FeatureHasher(input_type = 'string')\n",
      "print \"Step2: Hashing Frequency Table\"\n",
      "a = set(train)\n",
      "table = {}\n",
      "train = train.fillna('-999')\n",
      "test = test.fillna('-999')\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        table = freq(train[i], table)\n",
      "\n",
      "for i in a:\n",
      "    if i == 'id':\n",
      "        continue\n",
      "    if train[i].dtypes == 'object':\n",
      "        #print i\n",
      "        train[i] = lookup(table, train[i])\n",
      "        test[i] = lookup(table, test[i])\n",
      "\n",
      "\n",
      "print \"Starting Log Conversion\"\n",
      "# We convert the frequency into log scale and create pair-correlation\n",
      "\n",
      "def log_corr(data):\n",
      "    hash_cols = [3,4,34,35,61,64,65,91,94,95] # This one supposed have high correlation\n",
      "    \n",
      "    for i in range(10):\n",
      "        key = 'x' + str(hash_cols[i])\n",
      "        vec = pd.DataFrame(np.zeros(data.shape[0]), columns= ['log' + key], index=data.index)\n",
      "        print key, vec.shape, data.shape, len(data)\n",
      "        \n",
      "        for j in data.index:\n",
      "            num = data[key][j]\n",
      "            #print key, 'num = ', num\n",
      "\n",
      "            if num != -999.0:\n",
      "                vec['log' + key][j] = np.log(1.0 + num)\n",
      "                \n",
      "        data = pd.concat([data, vec], axis = 1)\n",
      "\n",
      "\n",
      "    for i in range(10):\n",
      "        key1 = 'logx' + str(hash_cols[i])\n",
      "        for j in range(i+1, 10):\n",
      "            key2 = 'logx' + str(hash_cols[j])\n",
      "            #print \"corr = \", key1, key2\n",
      "            \n",
      "            vec = pd.DataFrame(data[key1] * data[key2], columns=[key1 + key2], index=data.index)\n",
      "            data = pd.concat([data, vec], axis = 1)\n",
      "    \n",
      "    return data\n",
      "    \n",
      "# train\n",
      "\n",
      "train = log_corr(train)\n",
      "test = log_corr(test)\n",
      "\n",
      "# Split the train into training and validation\n",
      "split = 0.8\n",
      "rows = random.sample(train.index, int(split * nSample))\n",
      "\n",
      "temp = train\n",
      "train = temp.ix[rows]\n",
      "validation = temp.drop(rows)\n",
      "\n",
      "temp = label\n",
      "label = temp.ix[rows]\n",
      "label_validation = temp.drop(rows)\n",
      "del temp\n",
      "\n",
      "# scaling    \n",
      "#train[i] = preprocessing.scale(train[i].astype('float'))\n",
      "#validation[i] = preprocessing.scale(validation[i].astype('float'))\n",
      "#test[i] = preprocessing.scale(test[i].astype('float'))\n",
      "\n",
      "print train.shape\n",
      "print validation.shape\n",
      "print test.shape\n",
      "\n",
      "train.to_csv('train_log.csv', index = False)\n",
      "validation.to_csv('validation_log.csv', index = False)\n",
      "test.to_csv('test_log.csv', index = False)\n",
      "label.to_csv('label_vec.csv', index = False)\n",
      "label_validation.to_csv('label_validation_vec.csv', index = False)\n",
      "\n",
      "p1 = datetime.now()\n",
      "print('Sampling and hashing are done, elapsed time: %s' % str(p1 - start))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Step0: Loading raw data\n",
        "Data loading is done! elapsed time: 0:01:16.632000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Step1: Sampling\n",
        "Step2: Hashing Frequency Table"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting Log Conversion"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "x3 (100000, 1) (100000, 146) 100000\n",
        "x4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 147) 100000\n",
        "x34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 148) 100000\n",
        "x35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 149) 100000\n",
        "x61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 150) 100000\n",
        "x64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 151) 100000\n",
        "x65"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 152) 100000\n",
        "x91"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 153) 100000\n",
        "x94"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 154) 100000\n",
        "x95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (100000, 1) (100000, 155) 100000\n",
        "x3"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 146) 545082\n",
        "x4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 147) 545082\n",
        "x34"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 148) 545082\n",
        "x35"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 149) 545082\n",
        "x61"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 150) 545082\n",
        "x64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 151) 545082\n",
        "x65"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 152) 545082\n",
        "x91"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 153) 545082\n",
        "x94"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 154) 545082\n",
        "x95"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (545082, 1) (545082, 155) 545082\n",
        "(80000, 201)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(20000, 201)\n",
        "(545082, 201)\n",
        "Sampling and hashing are done, elapsed time: 0:15:01.365000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test.logx3.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0xd265630>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEACAYAAABcXmojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0xd265f98>"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "validation.logx3.hist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x41945f8>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDbk6CwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x1a0cd160>"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}